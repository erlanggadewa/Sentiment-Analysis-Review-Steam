model,preprocessing,epoch,train_loss,val_accuracy,val_mcc,val_macro_precision,val_macro_recall,val_macro_f1,test_accuracy,test_mcc,test_macro_precision,test_macro_recall,test_macro_f1
RoBERTa,No,1,0.22977237239829265,0.9651162790697675,0.929088747306122,0.9646443243623045,0.9644444444444444,0.964440620225824,0.9619140625,0.9220165964481054,0.9610165965974775,0.961,0.960999648996841
RoBERTa,No,2,0.10827780824741542,0.9600290697674418,0.9186405079641319,0.9593812568056483,0.9592592592592593,0.9592565542074398,0.97265625,0.9443702657304792,0.9723703383452627,0.972,0.9719945109241411
RoBERTa,No,3,0.046929841905997215,0.9680232558139535,0.935015948245874,0.9676085624762587,0.9674074074074074,0.967403901873672,0.96484375,0.92889961044531,0.9649000464900046,0.964,0.9639825675627003
RoBERTa,No,4,0.019902624180213026,0.9680232558139535,0.9348312290051892,0.9674238217418883,0.9674074074074074,0.9674071212696518,0.9697265625,0.9382270784327966,0.969227105919265,0.969,0.9689962485460741
RoBERTa,No,5,0.005616449413385756,0.96875,0.9363795337322341,0.9682313892840209,0.9681481481481482,0.968146732447368,0.970703125,0.9401880564188065,0.970188075230092,0.97,0.96999699969997
